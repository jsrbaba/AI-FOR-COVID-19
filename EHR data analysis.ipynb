{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the car data dataset\n",
    "try:\n",
    "    data1 = pd.read_csv(\"data/04-07_carbonhealth_and_braidhealth.csv\", delimiter=\",\")\n",
    "    print(\" dataset has {} samples with {} features each.\".format(*data1.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data2 = pd.read_csv(\"data/04-14_carbonhealth_and_braidhealth.csv\", delimiter=\",\")\n",
    "    print(\" dataset has {} samples with {} features each.\".format(*data2.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data3 = pd.read_csv(\"data/04-21_carbonhealth_and_braidhealth.csv\", delimiter=\",\")\n",
    "    print(\" dataset has {} samples with {} features each.\".format(*data3.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2, data3])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = list(data.select_dtypes(['bool']).columns)\n",
    "data[list_of_columns] = data[list_of_columns].apply(lambda col:pd.Categorical(col).codes)#.replace(-1,np.nan)\n",
    "#del data[\"cxr_findings\", \"cxr_impression\", \"cxr_link\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cough_severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cxr_impression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cancer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理成one-hot数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_onehot_columns = [\"swab_type\",\"test_name\", \"cough_severity\", \"sob_severity\", \n",
    "                         \"high_risk_exposure_occupation\", \"high_risk_interactions\", \"rapid_flu_results\", \n",
    "                         \"rapid_strep_results\", \"ctab\", \"labored_respiration\", \"rhonchi\", \"wheezes\", \"cough\",\n",
    "                         \"cough_severity\", \"fever\", \"sob\", \"sob_severity\", \"diarrhea\", \"fatigue\", \"headache\", \n",
    "                         \"loss_of_smell\", \"loss_of_taste\", \"runny_nose\", \"muscle_sore\", \"sore_throat\" ]\n",
    "onehot_columns_prefix = [\"swab_type\",\"test_name\", \"cough_severity\", \"sob_severity\",  \n",
    "                         \"high_risk_exposure_occupation\", \"high_risk_interactions\", \"rapid_flu_results\", \n",
    "                         \"rapid_strep_results\", \"ctab\", \"labored_respiration\", \"rhonchi\", \"wheezes\", \"cough\",\n",
    "                         \"cough_severity\", \"fever\", \"sob\", \"sob_severity\", \"diarrhea\", \"fatigue\", \"headache\", \n",
    "                         \"loss_of_smell\", \"loss_of_taste\", \"runny_nose\", \"muscle_sore\", \"sore_throat\"]\n",
    "\n",
    "one_hot_data = pd.get_dummies(data,prefix=onehot_columns_prefix, columns=person_onehot_columns)\n",
    "one_hot_data.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del one_hot_data[\"cxr_findings\"]\n",
    "del one_hot_data[\"cxr_impression\"]\n",
    "del one_hot_data[\"cxr_link\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.drop(one_hot_data[one_hot_data.age < 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.batch_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.covid19_test_results = pd.Categorical(one_hot_data.covid19_test_results)\n",
    "one_hot_data['target'] = one_hot_data.covid19_test_results.cat.codes\n",
    "#sub2['income'].fillna((sub2['income'].mean()), inplace=True)\n",
    "del one_hot_data[\"covid19_test_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data['days_since_symptom_onset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] <= 7, 1111)\n",
    "#one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] 7 > = 14, \"week2\")\n",
    "\n",
    "\n",
    "one_hot_data['days_since_symptom_onset'] = np.where(one_hot_data['days_since_symptom_onset'].between(8,14), 2222, one_hot_data['days_since_symptom_onset'])\n",
    "one_hot_data['days_since_symptom_onset'] = np.where(one_hot_data['days_since_symptom_onset'].between(15,21), 3333, one_hot_data['days_since_symptom_onset'])\n",
    "one_hot_data['days_since_symptom_onset'] = np.where(one_hot_data['days_since_symptom_onset'].between(22,28), 4444, one_hot_data['days_since_symptom_onset'])\n",
    "one_hot_data['days_since_symptom_onset'] = np.where(one_hot_data['days_since_symptom_onset'].between(29,35), 5555, one_hot_data['days_since_symptom_onset'])\n",
    "one_hot_data['days_since_symptom_onset'] = np.where(one_hot_data['days_since_symptom_onset'].between(36,150), 6666, one_hot_data['days_since_symptom_onset'])\n",
    "\n",
    "#one_hot_data['days_since_symptom_onset'].map({'1111': 'week1', '2222': 'week2','3333': 'week3', '4444': 'week4','5555': 'week5', '6666': 'week6'})\n",
    "\n",
    "\n",
    "#one_hot_data[one_hot_data.days_since_symptom_onset == '1111'] = 1 \n",
    "#w.female[w.female == 'male']   = 0\n",
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] == 1111, 1)\n",
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] == 2222, 2)\n",
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] == 3333, 3)\n",
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] == 4444, 4)\n",
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] == 5555, 5)\n",
    "one_hot_data['days_since_symptom_onset'] = one_hot_data['days_since_symptom_onset'].mask(one_hot_data['days_since_symptom_onset'] == 6666, 6)\n",
    "\n",
    "\n",
    "#one_hot_data['days_since_symptom_onset'].replace({'1111': 'week1', '2222': 'week2','3333': 'week3', '4444': 'week4','5555': 'week5', '6666': 'week6'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_onehot_columns = [\"days_since_symptom_onset\"]\n",
    "onehot_columns_prefix = [\"days_since_symptom_onset_week\"]\n",
    "\n",
    "one_hot_data_onset_sym = pd.get_dummies(one_hot_data,prefix=onehot_columns_prefix, columns=person_onehot_columns)\n",
    "one_hot_data_onset_sym.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data_onset_sym.temperature.fillna(one_hot_data_onset_sym.temperature.mean(), inplace=True)\n",
    "one_hot_data_onset_sym.sys.fillna(one_hot_data_onset_sym.sys.mean(), inplace=True)\n",
    "one_hot_data_onset_sym.dia.fillna(one_hot_data_onset_sym.dia.mean(), inplace=True)\n",
    "one_hot_data_onset_sym.rr.fillna(one_hot_data_onset_sym.rr.mean(), inplace=True)\n",
    "one_hot_data_onset_sym.sats.fillna(one_hot_data_onset_sym.sats.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = one_hot_data_onset_sym[[\"temperature\",\"pulse\",\"sys\", \"dia\",\"rr\",\"sats\"]]\n",
    "column_means = small_data.mean()\n",
    "small_data = small_data.fillna(column_means)\n",
    "small_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del one_hot_data_onset_sym[\"temperature\"]\n",
    "del one_hot_data_onset_sym[\"pulse\"]\n",
    "del one_hot_data_onset_sym[\"sys\"]\n",
    "del one_hot_data_onset_sym[\"dia\"]\n",
    "del one_hot_data_onset_sym[\"rr\"]\n",
    "del one_hot_data_onset_sym[\"sats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([one_hot_data_onset_sym, small_data], axis=1, sort=False)\n",
    "del final_df[\"batch_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_df[\"cxr_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(final_df.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('target')) #Remove b from list\n",
    "X = final_df[cols]\n",
    "y = final_df.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  preprocessing \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit(X_train)\n",
    "X_train_minmax = min_max_scaler.transform(X_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "#models.append(('pca', PCA()))\n",
    "models.append(('NN', MLPClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('GB', GradientBoostingClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed,shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig(\"fig1.png\")\n",
    "plt.savefig(\"fig1.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(X_train_minmax)\n",
    "X_test = pca.transform(X_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "#models.append(('pca', PCA()))\n",
    "models.append(('NN', MLPClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('GB', GradientBoostingClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed,shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.savefig(\"fig2.png\")\n",
    "plt.savefig(\"fig2.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"RF: Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"NN: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CART = DecisionTreeClassifier()\n",
    "CART.fit(X_train, y_train)\n",
    "predictions = CART.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"CART: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "predictions = gb.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"GB: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train, y_train)\n",
    "predictions = KNN.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"KNN: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(decision_function_shape=\"ovo\").fit(X_train, y_train)\n",
    "predictions = SVM.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"SVM: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train, y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"NB: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG = LogisticRegression()\n",
    "LG.fit(X_train, y_train)\n",
    "predictions = LG.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"LG: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_train, y_train)\n",
    "predictions = LDA.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"LDA: Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(100),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True,gamma=\"auto\"),\n",
    "    RandomForestClassifier(100),\n",
    "    DecisionTreeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "\n",
    "class_al =[]\n",
    "acc1 = []\n",
    "confusion_matrix_list = []\n",
    "labels = y.unique()\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    class_al.append(name)\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    acc1.append(acc)\n",
    "    matrix = confusion_matrix(y_test, train_predictions,labels=labels)\n",
    "\n",
    "    confusion_matrix_list.append(matrix)\n",
    "    \n",
    "max_acc = max(acc1) \n",
    "fig, ax = plt.subplots(figsize=(10,20))    \n",
    "plot=ax.bar(class_al,acc1)\n",
    "plot=ax.set_xlabel('Classification Al')\n",
    "plot=ax.set_ylabel('Accuracy')\n",
    "plot=ax.set_title('Classifier Accuracy')\n",
    "for tick in ax.get_xticklabels():\n",
    "    plot=tick.set_rotation(90)\n",
    "    \n",
    "plot=ax.axhline(y = max_acc,color = \"red\",linestyle=\"--\")\n",
    "plot=ax.annotate(\"Baseline Acc\", xy=(4.5,max_acc))\n",
    "\n",
    "\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"output.png\")\n",
    "fig.savefig(\"output.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其相关性结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "lasso = Lasso(max_iter = 10000, normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(scale(X_train), y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the coefficients are now reduced to exactly zero.\n",
    "pd.Series(lasso.coef_, index=X.columns).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
